#!/usr/bin/env python3
"""
NCCU æ©Ÿæˆ¿ç›£æ§ç³»çµ± - å„²å­˜ç©ºé–“æ¸…ç†å·¥å…·
æ‰‹å‹•å’Œè‡ªå‹•æ¸…ç†èˆŠæª”æ¡ˆï¼Œç®¡ç†å„²å­˜ç©ºé–“
"""

import os
import time
import shutil
import logging
from datetime import datetime, timedelta
from pathlib import Path
import argparse

class StorageCleanup:
    """å„²å­˜ç©ºé–“æ¸…ç†å·¥å…·"""
    
    def __init__(self, base_dir="captures", log_dir="logs"):
        self.base_dir = Path(base_dir)
        self.log_dir = Path(log_dir)
        self.base_dir.mkdir(exist_ok=True)
        self.log_dir.mkdir(exist_ok=True)
        
        # è¨­å®šæ—¥èªŒ
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - [CLEANUP] - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_dir / "cleanup.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def get_directory_info(self, directory):
        """å–å¾—ç›®éŒ„è³‡è¨Š"""
        try:
            directory = Path(directory)
            if not directory.exists():
                return None
            
            total_size = 0
            file_count = 0
            oldest_file = None
            newest_file = None
            
            for file_path in directory.rglob('*'):
                if file_path.is_file():
                    stat = file_path.stat()
                    total_size += stat.st_size
                    file_count += 1
                    
                    if oldest_file is None or stat.st_mtime < oldest_file[1]:
                        oldest_file = (file_path, stat.st_mtime)
                    
                    if newest_file is None or stat.st_mtime > newest_file[1]:
                        newest_file = (file_path, stat.st_mtime)
            
            return {
                'total_size_mb': total_size / 1024 / 1024,
                'file_count': file_count,
                'oldest_file': oldest_file[0] if oldest_file else None,
                'oldest_time': datetime.fromtimestamp(oldest_file[1]) if oldest_file else None,
                'newest_file': newest_file[0] if newest_file else None,
                'newest_time': datetime.fromtimestamp(newest_file[1]) if newest_file else None
            }
            
        except Exception as e:
            self.logger.error(f"å–å¾—ç›®éŒ„è³‡è¨Šå¤±æ•—: {e}")
            return None
    
    def cleanup_by_age(self, max_age_days, dry_run=False):
        """æŒ‰å¹´é½¡æ¸…ç†æª”æ¡ˆ"""
        cutoff_time = time.time() - (max_age_days * 24 * 3600)
        cutoff_date = datetime.fromtimestamp(cutoff_time)
        
        self.logger.info(f"æ¸…ç† {max_age_days} å¤©å‰çš„æª”æ¡ˆ (æ—©æ–¼ {cutoff_date.strftime('%Y-%m-%d %H:%M:%S')})")
        
        deleted_files = []
        deleted_size = 0
        
        try:
            for file_path in self.base_dir.rglob('*'):
                if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                    file_size = file_path.stat().st_size
                    file_age = datetime.fromtimestamp(file_path.stat().st_mtime)
                    
                    if dry_run:
                        self.logger.info(f"[æ¨¡æ“¬] å°‡åˆªé™¤: {file_path} ({file_size/1024/1024:.1f} MB, {file_age})")
                    else:
                        try:
                            file_path.unlink()
                            deleted_files.append(str(file_path))
                            deleted_size += file_size
                            self.logger.info(f"å·²åˆªé™¤: {file_path} ({file_size/1024/1024:.1f} MB)")
                        except Exception as e:
                            self.logger.error(f"åˆªé™¤æª”æ¡ˆå¤±æ•— {file_path}: {e}")
            
            if not dry_run and deleted_files:
                self.logger.info(f"å¹´é½¡æ¸…ç†å®Œæˆ: åˆªé™¤ {len(deleted_files)} å€‹æª”æ¡ˆ, é‡‹æ”¾ {deleted_size/1024/1024:.1f} MB")
            elif dry_run:
                self.logger.info(f"æ¨¡æ“¬æ¸…ç†: å°‡åˆªé™¤ {len(deleted_files)} å€‹æª”æ¡ˆ, å°‡é‡‹æ”¾ {deleted_size/1024/1024:.1f} MB")
            else:
                self.logger.info("æ²’æœ‰éœ€è¦æ¸…ç†çš„èˆŠæª”æ¡ˆ")
                
            return deleted_files, deleted_size
            
        except Exception as e:
            self.logger.error(f"å¹´é½¡æ¸…ç†å¤±æ•—: {e}")
            return [], 0
    
    def cleanup_by_size(self, max_size_mb, keep_recent_hours=24, dry_run=False):
        """æŒ‰å¤§å°æ¸…ç†æª”æ¡ˆï¼ˆä¿ç•™æœ€è¿‘çš„æª”æ¡ˆï¼‰"""
        max_size_bytes = max_size_mb * 1024 * 1024
        keep_recent_time = time.time() - (keep_recent_hours * 3600)
        
        self.logger.info(f"æ¸…ç†è¶…é {max_size_mb} MB çš„æª”æ¡ˆ (ä¿ç•™æœ€è¿‘ {keep_recent_hours} å°æ™‚)")
        
        # å–å¾—æ‰€æœ‰æª”æ¡ˆä¸¦æŒ‰æ™‚é–“æ’åº
        files_info = []
        total_size = 0
        
        for file_path in self.base_dir.rglob('*'):
            if file_path.is_file():
                stat = file_path.stat()
                files_info.append({
                    'path': file_path,
                    'size': stat.st_size,
                    'mtime': stat.st_mtime,
                    'is_recent': stat.st_mtime > keep_recent_time
                })
                total_size += stat.st_size
        
        if total_size <= max_size_bytes:
            self.logger.info(f"ç›®å‰å¤§å° {total_size/1024/1024:.1f} MB æœªè¶…éé™åˆ¶")
            return [], 0
        
        # æŒ‰æ™‚é–“æ’åºï¼ˆèˆŠçš„å…ˆåˆªé™¤ï¼‰ï¼Œä½†ä¿è­·æœ€è¿‘çš„æª”æ¡ˆ
        files_info.sort(key=lambda x: x['mtime'])
        
        deleted_files = []
        deleted_size = 0
        current_size = total_size
        
        for file_info in files_info:
            if current_size <= max_size_bytes:
                break
            
            # ä¿è­·æœ€è¿‘çš„æª”æ¡ˆ
            if file_info['is_recent']:
                self.logger.debug(f"ä¿è­·æœ€è¿‘æª”æ¡ˆ: {file_info['path']}")
                continue
            
            if dry_run:
                self.logger.info(f"[æ¨¡æ“¬] å°‡åˆªé™¤: {file_info['path']} ({file_info['size']/1024/1024:.1f} MB)")
            else:
                try:
                    file_info['path'].unlink()
                    deleted_files.append(str(file_info['path']))
                    deleted_size += file_info['size']
                    current_size -= file_info['size']
                    self.logger.info(f"å·²åˆªé™¤: {file_info['path']} ({file_info['size']/1024/1024:.1f} MB)")
                except Exception as e:
                    self.logger.error(f"åˆªé™¤æª”æ¡ˆå¤±æ•— {file_info['path']}: {e}")
        
        if not dry_run and deleted_files:
            self.logger.info(f"å¤§å°æ¸…ç†å®Œæˆ: åˆªé™¤ {len(deleted_files)} å€‹æª”æ¡ˆ, é‡‹æ”¾ {deleted_size/1024/1024:.1f} MB")
            self.logger.info(f"ç›®å‰å¤§å°: {current_size/1024/1024:.1f} MB")
        elif dry_run:
            target_size = current_size - deleted_size
            self.logger.info(f"æ¨¡æ“¬æ¸…ç†: å°‡åˆªé™¤ {len(deleted_files)} å€‹æª”æ¡ˆ, ç›®æ¨™å¤§å° {target_size/1024/1024:.1f} MB")
        
        return deleted_files, deleted_size
    
    def cleanup_empty_directories(self, dry_run=False):
        """æ¸…ç†ç©ºç›®éŒ„"""
        deleted_dirs = []
        
        try:
            # å¾æœ€æ·±å±¤é–‹å§‹æ¸…ç†
            for dir_path in sorted(self.base_dir.rglob('*'), key=lambda p: len(p.parts), reverse=True):
                if dir_path.is_dir() and dir_path != self.base_dir:
                    try:
                        # æª¢æŸ¥æ˜¯å¦ç‚ºç©ºç›®éŒ„
                        if not any(dir_path.iterdir()):
                            if dry_run:
                                self.logger.info(f"[æ¨¡æ“¬] å°‡åˆªé™¤ç©ºç›®éŒ„: {dir_path}")
                            else:
                                dir_path.rmdir()
                                deleted_dirs.append(str(dir_path))
                                self.logger.info(f"å·²åˆªé™¤ç©ºç›®éŒ„: {dir_path}")
                    except Exception as e:
                        self.logger.debug(f"ç„¡æ³•åˆªé™¤ç›®éŒ„ {dir_path}: {e}")
            
            if not dry_run and deleted_dirs:
                self.logger.info(f"æ¸…ç†ç©ºç›®éŒ„å®Œæˆ: åˆªé™¤ {len(deleted_dirs)} å€‹ç›®éŒ„")
            
            return deleted_dirs
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†ç©ºç›®éŒ„å¤±æ•—: {e}")
            return []
    
    def cleanup_log_files(self, max_log_age_days=14, max_log_size_mb=50, dry_run=False):
        """æ¸…ç†æ—¥èªŒæª”æ¡ˆ"""
        self.logger.info(f"æ¸…ç†æ—¥èªŒæª”æ¡ˆ: è¶…é {max_log_age_days} å¤©æˆ–ç¸½å¤§å°è¶…é {max_log_size_mb} MB")
        
        deleted_files = []
        deleted_size = 0
        
        try:
            # æŒ‰å¹´é½¡æ¸…ç†
            cutoff_time = time.time() - (max_log_age_days * 24 * 3600)
            log_files = []
            total_log_size = 0
            
            for log_file in self.log_dir.glob('*.log*'):
                if log_file.is_file():
                    stat = log_file.stat()
                    log_files.append({
                        'path': log_file,
                        'size': stat.st_size,
                        'mtime': stat.st_mtime
                    })
                    total_log_size += stat.st_size
                    
                    # æ¸…ç†éæœŸæ—¥èªŒ
                    if stat.st_mtime < cutoff_time:
                        if dry_run:
                            self.logger.info(f"[æ¨¡æ“¬] å°‡åˆªé™¤éæœŸæ—¥èªŒ: {log_file}")
                        else:
                            log_file.unlink()
                            deleted_files.append(str(log_file))
                            deleted_size += stat.st_size
                            self.logger.info(f"å·²åˆªé™¤éæœŸæ—¥èªŒ: {log_file}")
            
            # æŒ‰å¤§å°æ¸…ç†ï¼ˆä¿ç•™æœ€æ–°çš„æ—¥èªŒï¼‰
            max_log_size_bytes = max_log_size_mb * 1024 * 1024
            if total_log_size > max_log_size_bytes:
                # é‡æ–°æƒæï¼ˆæ’é™¤å·²åˆªé™¤çš„æª”æ¡ˆï¼‰
                current_log_files = []
                current_log_size = 0
                
                for log_file in self.log_dir.glob('*.log*'):
                    if log_file.is_file():
                        stat = log_file.stat()
                        current_log_files.append({
                            'path': log_file,
                            'size': stat.st_size,
                            'mtime': stat.st_mtime
                        })
                        current_log_size += stat.st_size
                
                # æŒ‰æ™‚é–“æ’åºï¼ˆèˆŠçš„å…ˆåˆªé™¤ï¼‰
                current_log_files.sort(key=lambda x: x['mtime'])
                
                for log_info in current_log_files:
                    if current_log_size <= max_log_size_bytes:
                        break
                    
                    # ä¿ç•™æœ€æ–°çš„ä¸»æ—¥èªŒæª”æ¡ˆ
                    if log_info['path'].name == 'monitor.log':
                        continue
                    
                    if dry_run:
                        self.logger.info(f"[æ¨¡æ“¬] å°‡åˆªé™¤æ—¥èªŒ: {log_info['path']} ({log_info['size']/1024/1024:.1f} MB)")
                    else:
                        try:
                            log_info['path'].unlink()
                            deleted_files.append(str(log_info['path']))
                            deleted_size += log_info['size']
                            current_log_size -= log_info['size']
                            self.logger.info(f"å·²åˆªé™¤æ—¥èªŒ: {log_info['path']}")
                        except Exception as e:
                            self.logger.error(f"åˆªé™¤æ—¥èªŒå¤±æ•— {log_info['path']}: {e}")
            
            if not dry_run and deleted_files:
                self.logger.info(f"æ—¥èªŒæ¸…ç†å®Œæˆ: åˆªé™¤ {len(deleted_files)} å€‹æª”æ¡ˆ, é‡‹æ”¾ {deleted_size/1024/1024:.1f} MB")
            
            return deleted_files, deleted_size
            
        except Exception as e:
            self.logger.error(f"æ—¥èªŒæ¸…ç†å¤±æ•—: {e}")
            return [], 0
    
    def run_comprehensive_cleanup(self, max_age_days=7, max_size_mb=500, max_log_age_days=14, dry_run=False):
        """åŸ·è¡Œç¶œåˆæ¸…ç†"""
        self.logger.info("=" * 60)
        self.logger.info("é–‹å§‹ç¶œåˆå„²å­˜ç©ºé–“æ¸…ç†")
        self.logger.info("=" * 60)
        
        if dry_run:
            self.logger.info("ğŸ” æ¨¡æ“¬æ¨¡å¼ - ä¸æœƒå¯¦éš›åˆªé™¤æª”æ¡ˆ")
        
        # æ¸…ç†å‰ç‹€æ…‹
        before_info = self.get_directory_info(self.base_dir)
        if before_info:
            self.logger.info(f"æ¸…ç†å‰ç‹€æ…‹: {before_info['file_count']} å€‹æª”æ¡ˆ, {before_info['total_size_mb']:.1f} MB")
        
        total_deleted_files = 0
        total_freed_mb = 0
        
        # 1. æŒ‰å¹´é½¡æ¸…ç†
        self.logger.info("\n1ï¸âƒ£ æŒ‰å¹´é½¡æ¸…ç†æª”æ¡ˆ...")
        age_files, age_size = self.cleanup_by_age(max_age_days, dry_run)
        total_deleted_files += len(age_files)
        total_freed_mb += age_size / 1024 / 1024
        
        # 2. æŒ‰å¤§å°æ¸…ç†
        self.logger.info("\n2ï¸âƒ£ æŒ‰å¤§å°æ¸…ç†æª”æ¡ˆ...")
        size_files, size_size = self.cleanup_by_size(max_size_mb, dry_run=dry_run)
        total_deleted_files += len(size_files)
        total_freed_mb += size_size / 1024 / 1024
        
        # 3. æ¸…ç†ç©ºç›®éŒ„
        self.logger.info("\n3ï¸âƒ£ æ¸…ç†ç©ºç›®éŒ„...")
        empty_dirs = self.cleanup_empty_directories(dry_run)
        
        # 4. æ¸…ç†æ—¥èªŒæª”æ¡ˆ
        self.logger.info("\n4ï¸âƒ£ æ¸…ç†æ—¥èªŒæª”æ¡ˆ...")
        log_files, log_size = self.cleanup_log_files(max_log_age_days, dry_run=dry_run)
        total_freed_mb += log_size / 1024 / 1024
        
        # æ¸…ç†å¾Œç‹€æ…‹
        after_info = self.get_directory_info(self.base_dir)
        
        self.logger.info("\n" + "=" * 60)
        self.logger.info("æ¸…ç†æ‘˜è¦")
        self.logger.info("=" * 60)
        
        if not dry_run:
            self.logger.info(f"âœ… åˆªé™¤æª”æ¡ˆ: {total_deleted_files} å€‹")
            self.logger.info(f"âœ… é‡‹æ”¾ç©ºé–“: {total_freed_mb:.1f} MB")
            self.logger.info(f"âœ… åˆªé™¤ç©ºç›®éŒ„: {len(empty_dirs)} å€‹")
            
            if before_info and after_info:
                size_reduction = before_info['total_size_mb'] - after_info['total_size_mb']
                self.logger.info(f"ğŸ“Š ç©ºé–“è®ŠåŒ–: {before_info['total_size_mb']:.1f} MB â†’ {after_info['total_size_mb']:.1f} MB")
                self.logger.info(f"ğŸ“Š å¯¦éš›é‡‹æ”¾: {size_reduction:.1f} MB")
        else:
            self.logger.info(f"ğŸ” æ¨¡æ“¬çµæœ: å°‡åˆªé™¤ {total_deleted_files} å€‹æª”æ¡ˆ")
            self.logger.info(f"ğŸ” æ¨¡æ“¬çµæœ: å°‡é‡‹æ”¾ {total_freed_mb:.1f} MB")
        
        return {
            'deleted_files': total_deleted_files,
            'freed_mb': total_freed_mb,
            'deleted_dirs': len(empty_dirs)
        }

def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description="NCCU ç›£æ§ç³»çµ±å„²å­˜ç©ºé–“æ¸…ç†å·¥å…·")
    
    parser.add_argument("--age", type=int, default=7, help="æ¸…ç† N å¤©å‰çš„æª”æ¡ˆ (é è¨­: 7)")
    parser.add_argument("--size", type=int, default=500, help="ä¿æŒç¸½å¤§å°åœ¨ N MB ä»¥ä¸‹ (é è¨­: 500)")
    parser.add_argument("--log-age", type=int, default=14, help="æ¸…ç† N å¤©å‰çš„æ—¥èªŒ (é è¨­: 14)")
    parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ“¬æ¨¡å¼ï¼Œä¸å¯¦éš›åˆªé™¤æª”æ¡ˆ")
    parser.add_argument("--info", action="store_true", help="åªé¡¯ç¤ºç›®éŒ„è³‡è¨Š")
    parser.add_argument("--age-only", action="store_true", help="åªæŒ‰å¹´é½¡æ¸…ç†")
    parser.add_argument("--size-only", action="store_true", help="åªæŒ‰å¤§å°æ¸…ç†")
    parser.add_argument("--logs-only", action="store_true", help="åªæ¸…ç†æ—¥èªŒ")
    
    args = parser.parse_args()
    
    cleanup = StorageCleanup()
    
    if args.info:
        print("ğŸ“Š ç›®éŒ„è³‡è¨Š")
        print("=" * 40)
        
        # Captures ç›®éŒ„
        captures_info = cleanup.get_directory_info("captures")
        if captures_info:
            print(f"Captures ç›®éŒ„:")
            print(f"  æª”æ¡ˆæ•¸: {captures_info['file_count']}")
            print(f"  ç¸½å¤§å°: {captures_info['total_size_mb']:.1f} MB")
            if captures_info['oldest_time']:
                print(f"  æœ€èˆŠæª”æ¡ˆ: {captures_info['oldest_time'].strftime('%Y-%m-%d %H:%M:%S')}")
            if captures_info['newest_time']:
                print(f"  æœ€æ–°æª”æ¡ˆ: {captures_info['newest_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ—¥èªŒç›®éŒ„
        logs_info = cleanup.get_directory_info("logs")
        if logs_info:
            print(f"\næ—¥èªŒç›®éŒ„:")
            print(f"  æª”æ¡ˆæ•¸: {logs_info['file_count']}")
            print(f"  ç¸½å¤§å°: {logs_info['total_size_mb']:.1f} MB")
        
    elif args.age_only:
        cleanup.cleanup_by_age(args.age, args.dry_run)
    elif args.size_only:
        cleanup.cleanup_by_size(args.size, dry_run=args.dry_run)
    elif args.logs_only:
        cleanup.cleanup_log_files(args.log_age, dry_run=args.dry_run)
    else:
        cleanup.run_comprehensive_cleanup(
            max_age_days=args.age,
            max_size_mb=args.size,
            max_log_age_days=args.log_age,
            dry_run=args.dry_run
        )

if __name__ == "__main__":
    main()